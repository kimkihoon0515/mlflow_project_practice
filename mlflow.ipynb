{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import mlflow # mlflow 사용을 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784,100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.fc3 = nn.Linear(100,10)\n",
    "    def forward(self, x):\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.relu(x1)\n",
    "        x3 = self.fc2(x2)\n",
    "        x4 = self.relu(x3)\n",
    "        x5 = self.fc3(x4)\n",
    "\n",
    "        return x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 정의  \n",
    "## MNIST Dataset을 사용하여 학습,검증을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root = 'MNIST_data/'\n",
    "\n",
    "train_dataset = datasets.MNIST(root=download_root,\n",
    "                         train=True,\n",
    "                         transform = transforms.ToTensor(),\n",
    "                         download=True)\n",
    "                         \n",
    "test_dataset = datasets.MNIST(root=download_root,\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch_size, Train, Test Dataloader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습률, Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.zero_grad()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.03\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed 고정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow를 활용하여 학습진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Model(Epoch: 1, Accuracy: 87.84)\n",
      "epoch : 1 | loss : 1.215651\n",
      "Accuracy : 87.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 45] Operation not supported: '/home/khkim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m       mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m'\u001b[39m\u001b[39mvalid_accuracy\u001b[39m\u001b[39m'\u001b[39m,accuracy)\n\u001b[1;32m     83\u001b[0m       mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m'\u001b[39m\u001b[39mvalid_loss\u001b[39m\u001b[39m'\u001b[39m,avg_cost)\n\u001b[0;32m---> 84\u001b[0m       mlflow\u001b[39m.\u001b[39;49mpytorch\u001b[39m.\u001b[39;49mlog_model(model,\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# pytorch.log_model 을 통해 모델을 저장할 수 있습니다.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m       \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m mlflow\u001b[39m.\u001b[39mend_run()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/mlflow/pytorch/__init__.py:306\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(pytorch_model, artifact_path, conda_env, code_paths, pickle_module, registered_model_name, signature, input_example, await_registration_for, requirements_file, extra_files, pip_requirements, extra_pip_requirements, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39mLog a PyTorch model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39m    PyTorch logged models\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    305\u001b[0m pickle_module \u001b[39m=\u001b[39m pickle_module \u001b[39mor\u001b[39;00m mlflow_pytorch_pickle_module\n\u001b[0;32m--> 306\u001b[0m \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49mlog(\n\u001b[1;32m    307\u001b[0m     artifact_path\u001b[39m=\u001b[39;49martifact_path,\n\u001b[1;32m    308\u001b[0m     flavor\u001b[39m=\u001b[39;49mmlflow\u001b[39m.\u001b[39;49mpytorch,\n\u001b[1;32m    309\u001b[0m     pytorch_model\u001b[39m=\u001b[39;49mpytorch_model,\n\u001b[1;32m    310\u001b[0m     conda_env\u001b[39m=\u001b[39;49mconda_env,\n\u001b[1;32m    311\u001b[0m     code_paths\u001b[39m=\u001b[39;49mcode_paths,\n\u001b[1;32m    312\u001b[0m     pickle_module\u001b[39m=\u001b[39;49mpickle_module,\n\u001b[1;32m    313\u001b[0m     registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[1;32m    314\u001b[0m     signature\u001b[39m=\u001b[39;49msignature,\n\u001b[1;32m    315\u001b[0m     input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[1;32m    316\u001b[0m     await_registration_for\u001b[39m=\u001b[39;49mawait_registration_for,\n\u001b[1;32m    317\u001b[0m     requirements_file\u001b[39m=\u001b[39;49mrequirements_file,\n\u001b[1;32m    318\u001b[0m     extra_files\u001b[39m=\u001b[39;49mextra_files,\n\u001b[1;32m    319\u001b[0m     pip_requirements\u001b[39m=\u001b[39;49mpip_requirements,\n\u001b[1;32m    320\u001b[0m     extra_pip_requirements\u001b[39m=\u001b[39;49mextra_pip_requirements,\n\u001b[1;32m    321\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    322\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/mlflow/models/model.py:374\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m mlflow_model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(artifact_path\u001b[39m=\u001b[39martifact_path, run_id\u001b[39m=\u001b[39mrun_id)\n\u001b[1;32m    373\u001b[0m flavor\u001b[39m.\u001b[39msave_model(path\u001b[39m=\u001b[39mlocal_path, mlflow_model\u001b[39m=\u001b[39mmlflow_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 374\u001b[0m mlflow\u001b[39m.\u001b[39;49mtracking\u001b[39m.\u001b[39;49mfluent\u001b[39m.\u001b[39;49mlog_artifacts(local_path, mlflow_model\u001b[39m.\u001b[39;49martifact_path)\n\u001b[1;32m    375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39m_record_logged_model(mlflow_model)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/mlflow/tracking/fluent.py:810\u001b[0m, in \u001b[0;36mlog_artifacts\u001b[0;34m(local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[39mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[39mthis method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39m        mlflow.log_artifacts(\"data\", artifact_path=\"states\")\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    809\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m--> 810\u001b[0m MlflowClient()\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/mlflow/tracking/client.py:1182\u001b[0m, in \u001b[0;36mMlflowClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\n\u001b[1;32m   1139\u001b[0m     \u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m, local_dir: \u001b[39mstr\u001b[39m, artifact_path: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[39m        is_dir: True\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:469\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\u001b[39mself\u001b[39m, run_id, local_dir, artifact_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[1;32m    466\u001b[0m \u001b[39m    :param local_dir: Path to the directory of files to write.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m    :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_artifact_repo(run_id)\u001b[39m.\u001b[39;49mlog_artifacts(local_dir, artifact_path)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py:57\u001b[0m, in \u001b[0;36mLocalArtifactRepository.log_artifacts\u001b[0;34m(self, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m artifact_dir \u001b[39m=\u001b[39m (\n\u001b[1;32m     54\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39martifact_dir, artifact_path) \u001b[39mif\u001b[39;00m artifact_path \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39martifact_dir\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(artifact_dir):\n\u001b[0;32m---> 57\u001b[0m     mkdir(artifact_dir)\n\u001b[1;32m     58\u001b[0m dir_util\u001b[39m.\u001b[39mcopy_tree(src\u001b[39m=\u001b[39mlocal_dir, dst\u001b[39m=\u001b[39martifact_dir, preserve_mode\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, preserve_times\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/mlflow/utils/file_utils.py:120\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m errno\u001b[39m.\u001b[39mEEXIST \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(target):\n\u001b[0;32m--> 120\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    121\u001b[0m \u001b[39mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/mlflow/utils/file_utils.py:117\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    115\u001b[0m target \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, name) \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m root\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(target)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m errno\u001b[39m.\u001b[39mEEXIST \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(target):\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 45] Operation not supported: '/home/khkim'"
     ]
    }
   ],
   "source": [
    "experiment_name = 'chaos_AIP' # 실험명, 실험관리를 용이하게 해줍니다. \n",
    "\n",
    "\n",
    "if not mlflow.get_experiment_by_name(experiment_name): \n",
    "  mlflow.create_experiment(name=experiment_name)\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000') # 로컬 서버에 실행을 기록하기 위해 함수 호출\n",
    "#mlflow.set_tag(\"mlflow.runName\",\"practice\")\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "total_batch = len(train_loader)\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "best_accuracy = 0\n",
    "with mlflow.start_run(experiment_id=experiment.experiment_id,run_name=\"boom\"):\n",
    "  for epoch in range(epochs):\n",
    "      cost=0\n",
    "      model.train()\n",
    "      train_accuracy = 0\n",
    "      train_loss = 0\n",
    "      for images, labels in train_loader:\n",
    "          images = images.reshape(100,784)\n",
    "          \n",
    "          optimizer.zero_grad() # 변화도 매개변수 0\n",
    "          \n",
    "          #forward\n",
    "          #pred = model.forward(images)\n",
    "          #loss = loss_function(pred, labels)\n",
    "          pred = model(images)\n",
    "          loss = loss_function(pred,labels)\n",
    "          prediction = torch.argmax(pred,1)\n",
    "          correct = (prediction == labels)\n",
    "          train_accuracy += correct.sum().item() / 60000\n",
    "          train_loss += loss.item() / 600\n",
    "          \n",
    "          #backward\n",
    "          loss.backward()\n",
    "          \n",
    "          #Update\n",
    "          optimizer.step()\n",
    "          \n",
    "          cost += loss\n",
    "      \n",
    "      with torch.no_grad(): #미분하지 않겠다는 것\n",
    "          total = 0\n",
    "          correct=0\n",
    "          for images, labels in test_loader:\n",
    "              images = images.reshape(100,784)\n",
    "\n",
    "              outputs = model(images)\n",
    "              _,predict = torch.max(outputs.data, 1)\n",
    "\n",
    "              total += labels.size(0)\n",
    "              correct += (predict==labels).sum() # 예측한 값과 일치한 값의 합\n",
    "\n",
    "      avg_cost = cost / total_batch\n",
    "      accuracy = 100*correct/total\n",
    "      \n",
    "      val_loss_list.append(avg_cost.detach().numpy())\n",
    "      val_acc_list.append(accuracy)\n",
    "\n",
    "      if accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(),'model.pt')\n",
    "        mlflow.pytorch.log_model(model,'model') # pytorch.log_model 을 통해 모델을 저장할 수 있습니다.\n",
    "        best_accuracy = accuracy\n",
    "        print(f\"Save Model(Epoch: {epoch+1}, Accuracy: {best_accuracy:.5})\")\n",
    "      \n",
    "      print(\"epoch : {} | loss : {:.6f}\" .format(epoch+1, avg_cost))\n",
    "      print(\"Accuracy : {:.2f}\".format(100*correct/total))\n",
    "      mlflow.log_param('learning-rate',learning_rate) # mlflow.log_param 을 사용하여 MLflow에 파라미터들을 기록할 수 있습니다.\n",
    "      mlflow.log_param('epoch',epochs)\n",
    "      mlflow.log_param('batch_size',batch_size)\n",
    "      mlflow.log_param('seed',seed)\n",
    "      mlflow.log_metric('train_accuracy',train_accuracy) # mlflow.log_metric을 사용하여 MLflow에 성능평가를 위한 metric을 기록할 수 있습니다.\n",
    "      mlflow.log_metric('train_loss',train_loss)\n",
    "      mlflow.log_metric('valid_accuracy',accuracy)\n",
    "      mlflow.log_metric('valid_loss',avg_cost)\n",
    "      print(\"------\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import bentoml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"mnist_clf:pycdv6sy3wh6f2kn\", path=\"/home/khkim/bentoml/models/mnist_clf/pycdv6sy3wh6f2kn/\")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLFLOW_PATH = './model_mlflow'\n",
    "\n",
    "if not os.path.isdir(MLFLOW_PATH):\n",
    "  mlflow.pytorch.save_model(model, MLFLOW_PATH) # mlflow 모델 로컬 디렉토리에 저장\n",
    "\n",
    "bentoml.mlflow.import_model(\"mnist_clf\", model_uri='./model_mlflow') # mlflow로 저장한 모델을 bentoml format에 맞추어 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[0m\u001b[1mTag                       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\n",
      " mnist_clf:pycdv6sy3wh6f2kn  bentoml.mlflow  355.39 KiB  2022-10-31 14:33:04 \n",
      " mnist_clf:klquv2syykh6f2kn  bentoml.mlflow  355.39 KiB  2022-10-31 11:18:35 \n",
      " mnist_clf:xkvy4zsyygh6f2kn  bentoml.mlflow  355.39 KiB  2022-10-31 11:14:20 \n",
      " mnist_clf:v65qkwsyych6f2kn  bentoml.mlflow  355.39 KiB  2022-10-31 11:06:52 \n"
     ]
    }
   ],
   "source": [
    "!bentoml models list mnist_clf # 현재 등록되어 있는 모델 리스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 테스트 데이터 가져오기\n",
    "with open('./test_input_arr.json', 'r') as f:\n",
    "  test_input_arr = np.array(json.load(f), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Runner.init_local' is for debugging and testing only.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -0.40538397,  -3.2523298 ,   3.0703802 ,   5.5641313 ,\n",
       "         -5.7938633 ,   0.3673871 , -12.363699  ,  11.423534  ,\n",
       "          1.1209784 ,   2.2345915 ],\n",
       "       [  2.5325568 ,   5.260461  ,  11.839561  ,   5.9065714 ,\n",
       "        -12.815116  ,   0.8554225 ,   3.3562913 ,  -7.457034  ,\n",
       "          1.7260301 , -12.618624  ],\n",
       "       [ -5.5542216 ,   7.381215  ,   0.96818936,  -0.879593  ,\n",
       "         -1.4426495 ,  -1.2838367 ,   0.17502701,   2.1546166 ,\n",
       "          1.496681  ,  -2.1817076 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 테스트\n",
    "runner = bentoml.mlflow.get(\"mnist_clf:latest\").to_runner()\n",
    "runner.init_local()\n",
    "runner.predict.run(test_input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.258671</td>\n",
       "      <td>-2.587523</td>\n",
       "      <td>3.675304</td>\n",
       "      <td>5.038008</td>\n",
       "      <td>-6.668222</td>\n",
       "      <td>-1.726515</td>\n",
       "      <td>-13.880798</td>\n",
       "      <td>11.955110</td>\n",
       "      <td>0.665868</td>\n",
       "      <td>2.337876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.636475</td>\n",
       "      <td>5.572082</td>\n",
       "      <td>13.566373</td>\n",
       "      <td>6.943092</td>\n",
       "      <td>-14.104278</td>\n",
       "      <td>3.698562</td>\n",
       "      <td>5.460308</td>\n",
       "      <td>-10.887386</td>\n",
       "      <td>4.345160</td>\n",
       "      <td>-11.610110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.794973</td>\n",
       "      <td>6.889330</td>\n",
       "      <td>1.424413</td>\n",
       "      <td>-0.571910</td>\n",
       "      <td>-0.550162</td>\n",
       "      <td>-1.709335</td>\n",
       "      <td>-1.310455</td>\n",
       "      <td>1.598313</td>\n",
       "      <td>1.397186</td>\n",
       "      <td>-2.306628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2         3          4         5          6  \\\n",
       "0 -0.258671 -2.587523   3.675304  5.038008  -6.668222 -1.726515 -13.880798   \n",
       "1  2.636475  5.572082  13.566373  6.943092 -14.104278  3.698562   5.460308   \n",
       "2 -4.794973  6.889330   1.424413 -0.571910  -0.550162 -1.709335  -1.310455   \n",
       "\n",
       "           7         8          9  \n",
       "0  11.955110  0.665868   2.337876  \n",
       "1 -10.887386  4.345160 -11.610110  \n",
       "2   1.598313  1.397186  -2.306628  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_model = 'runs:/f35718cb70f542aa8b59eca0cc7e1a70/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "loaded_model.predict(pd.DataFrame(test_input_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31T11:18:42+0900 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"service:svc\" can be accessed at http://localhost:3000/metrics.\n",
      "2022-10-31T11:18:43+0900 [INFO] [cli] Starting development HTTP BentoServer from \"service:svc\" running on http://0.0.0.0:3000 (Press CTRL+C to quit)\n",
      "2022-10-31 11:18:44 circus[2119121] [INFO] Loading the plugin...\n",
      "2022-10-31 11:18:44 circus[2119121] [INFO] Endpoint: 'tcp://127.0.0.1:36727'\n",
      "2022-10-31 11:18:44 circus[2119121] [INFO] Pub/sub: 'tcp://127.0.0.1:39683'\n",
      "2022-10-31T11:18:44+0900 [INFO] [observer] Watching directories: ['/home/khkim/aip/AIP', '/home/khkim/bentoml/models']\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service:svc --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
